# Production environment configuration
# Overrides base.yaml settings for production deployment

# Example: Use larger models and batch sizes for production
llm:
  query_model:
    platform: "openai"
    name: "gpt-5-nano-2025-08-07"
  embedding_model:
    name: "text-embedding-3-small"
    platform: "openai"
    tokenizer: "cl100k_base"

index:
  insert_batch_size: 4096

query_engine:
  similarity_top_k: 3
  similarity_cutoff: 0.7  # Enable similarity filtering in production

# Production data paths
# data:
#   folder_path: "/var/lib/nzambe/data/bible"
